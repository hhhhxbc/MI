{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\huawei/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_vgg16_bn\", pretrained=True)\n",
    "model.load_state_dict(torch.load(\"VGG16_cifar100_sigmoid_origin_1.pth\"))\n",
    "hout = np.load('Hout_VGG16_train.npy', allow_pickle=True)\n",
    "hout = [np.array(h, dtype=np.float32) for h in hout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def gH(cov, covv=None, mu=np.nan, muu=np.nan):\n",
    "    if cov.ndim == 0:\n",
    "        det = cov\n",
    "    else:\n",
    "        raise ValueError(\"cov should be 0D array\")\n",
    "    if det == 0: det = 1e-10\n",
    "\n",
    "    if covv == None:  \n",
    "        return 0.5 * (1 + np.log(2*np.pi)) + 0.5 * np.log(det)\n",
    "    \n",
    "    if covv.ndim == 0:\n",
    "        dett = covv\n",
    "    else:\n",
    "        raise ValueError(\"covv should be 0D array\")\n",
    "    if dett == 0: dett = 1e-10\n",
    "    return 0.5 * (np.log(2*np.pi)) + 0.5 * np.log(dett) + 0.5 * ((mu-muu)**2 + det) / dett\n",
    "\n",
    "def Hy(X, n=30):\n",
    "    clf = GaussianMixture(n_components=n, covariance_type='diag', random_state=1)\n",
    "    clf.fit(X)\n",
    "    h = 0\n",
    "    cov = clf.covariances_.ravel()\n",
    "    mu = clf.means_.ravel()\n",
    "    w = clf.weights_.ravel()\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            h += w[i] * w[j] * gH(cov[i], cov[j], mu[i], mu[j])\n",
    "    return h\n",
    "\n",
    "def Hx(p):\n",
    "    return np.sum(-p * np.log(p)/np.log(2))\n",
    "\n",
    "def MI(px, y, xy):\n",
    "    return Hx(px) + Hy(y) - Hy(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([len(h) for h in hout])\n",
    "px = x / x.sum()\n",
    "y = np.concatenate(hout, axis=0)\n",
    "xy = np.concatenate([np.c_[hout[i],[i for _ in hout[i]]] for i in range(len(hout))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hy_x(xy, n=3):\n",
    "    xy = [xy[xy[:,-1]==i][:,:-1] for i in range(len(hout))]\n",
    "    hy_x = 0\n",
    "    for i, h in enumerate(xy):\n",
    "        hy_x += Hy(h, n)*px[i]\n",
    "    return hy_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hyy(xy, n=3):\n",
    "    xy = [xy[xy[:,-1]==i][:,:-1] for i in range(len(hout))]\n",
    "    cov = []\n",
    "    mu = []\n",
    "    w = []\n",
    "    for i, h in enumerate(xy):\n",
    "        clf = GaussianMixture(n_components=n, covariance_type='diag', random_state=1)\n",
    "        clf.fit(h)\n",
    "        for k in range(n):\n",
    "            cov.append(clf.covariances_.ravel()[k])\n",
    "            mu.append(clf.means_.ravel()[k])\n",
    "            w.append(clf.weights_.ravel()[k] * px[i])\n",
    "    h = 0\n",
    "    for i in range(len(w)):\n",
    "        for j in range(len(w)):\n",
    "            h += w[i] * w[j] * gH(cov[i], cov[j], mu[i], mu[j])\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MIxy(sli):\n",
    "    # return Hyy(xy[:,sli+[-1]])-Hy_x(xy[:,sli+[-1]]) \n",
    "    # 0.55641402, 0.04674744\n",
    "    return Hy(y[:,sli])-Hy_x(xy[:,sli+[-1]])\n",
    "    # 0.67405948, 0.05763917 30 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [19:24<00:00,  2.27s/it]\n"
     ]
    }
   ],
   "source": [
    "# 不同神经元与最终输出的互信息\n",
    "from tqdm import tqdm\n",
    "MIs = []\n",
    "for i in tqdm(range(y.shape[1])):\n",
    "    MIs.append(MIxy([i]))\n",
    "MIs = np.array(MIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate(hout, axis=0)\n",
    "hvar = [y[:, i].var() for i in range(y.shape[1])] # Task Variance\n",
    "hvar = np.array(hvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = model.classifier[6].bias.data.cpu().numpy()\n",
    "W = model.classifier[6].weight.data.cpu().numpy()\n",
    "B = np.tile(b/W.shape[1], (W.shape[1],1)).T # 认为每条连接对bias的贡献相同\n",
    "b_ = B / W\n",
    "b_ = b_.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.67405948, 0.05763917],\n",
       "       [0.67405948, 1.        , 0.09920422],\n",
       "       [0.05763917, 0.09920422, 1.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef([MIs, hvar, b_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SignificanceResult(statistic=0.6839239758929286, pvalue=7.431099647394277e-72),\n",
       " PearsonRResult(statistic=0.674059478107472, pvalue=4.26665438743269e-69),\n",
       " SignificanceResult(statistic=0.017767556734301505, pvalue=0.6883590572119154),\n",
       " PearsonRResult(statistic=0.057639171445923384, pvalue=0.19287517331417617),\n",
       " SignificanceResult(statistic=0.04720983036930225, pvalue=0.28632413217271147),\n",
       " PearsonRResult(statistic=0.09920421798866629, pvalue=0.024781708081683142))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "# 斯皮尔曼相关系数，皮尔逊相关系数\n",
    "stats.spearmanr(MIs, hvar), stats.pearsonr(MIs, hvar), \\\n",
    "stats.spearmanr(MIs, b_), stats.pearsonr(MIs, b_), \\\n",
    "stats.spearmanr(hvar, b_), stats.pearsonr(hvar, b_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
